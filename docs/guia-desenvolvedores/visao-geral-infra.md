E a√≠, quer entender melhor nossa infraestrutura de dados, os componentes selecionados, como interagem
entre si e onde est√£o hospedados? Ent√£o vamos l√°! üë®‚Äçüíª

## Introdu√ß√£o ao fluxo de dados

N√£o h√° nada extravagante em nosso fluxo de dados, na realidade, ele √© t√£o intuitivo quanto pode ser.
No entanto, √© muito importante entender cada etapa para que seja poss√≠vel compreender o funcionamento
da infraestrutura como um todo.

Ent√£o, vamos colocar aqui um diagrama que ajudar√° a entender por onde o dado transita e no que consistem
as etapas:

![Diagrama de etapas de processamento dos dados](../static/img/tutoriais/visao-geral-infra/visao-geral-sem-componentes.jpg)

Como estamos falando sobre a infraestrutura de dados, vamos focar √∫nica e exclusivamente na parte
central desse diagrama, ou seja, as tr√™s grandes etapas - Ingest√£o, Transforma√ß√£o e Aplica√ß√£o - e o
bloco central, o Armaz√©m de Dados.

### Armaz√©m de dados

Como o pr√≥prio nome j√° diz, √© o local onde os dados s√£o armazenados. No entanto, n√£o √© uma ferramenta
t√£o simples quanto o nome faz parecer, dado que √© o componente central do fluxo de dados e, portanto,
deve suportar uma grande variedade de opera√ß√µes, al√©m de uma imensa capacidade de processamento e
armazenamento, visto que os dados podem ter tamanhos e prioridades diferentes.

Mais especificamente, uma ferramenta de armaz√©m de dados para nossa infraestrutura deve possuir as
seguintes funcionalidades:

- **Capacidade de armazenamento e processamento "ilimitada"**: n√£o queremos nos preocupar em qual o tamanho do dado
  que vamos armazenar, n√≥s o queremos e ponto!
- **Otimiza√ß√£o de processamento via particionamento e correlatos**: para dados de grande volume, √©
  sempre interessante recorrer a mecanismos de particionamento e semelhantes para otimizar o processamento
  e, consequentemente, os custos de uma consulta.
- **Suporte a SQL**: n√≥s queremos usar a linguagem de consulta mais popular e acess√≠vel at√© o momento.
- **Fun√ß√µes de an√°lise geoespacial**: por se tratar de dados da cidade s√£o, em maioria, geolocalizados.
  Assim, ter funcionalidades de an√°lise geoespacial √© fundamental.
- **Governan√ßa simplificada**: ter uma interface amig√°vel para gerir o armaz√©m de dados √© fundamental.
- **Conex√µes com plataformas de desenvolvimento de dashboards**: n√£o adianta ter dados se n√£o conseguimos
  visualiz√°-los ou us√°-los.
- **Possibilidade de disponibilizar os dados publicamente**: afinal, queremos que a comunidade acesse!

### Ingest√£o

A ingest√£o √© o ato de obter um dado e traz√™-lo para seu ambiente. Ela consiste em duas subetapas: a
extra√ß√£o e o armazenamento.

A **Extra√ß√£o** √© ato de adquirir o dado a partir de alguma fonte, como um banco de dados, uma API ou
um arquivo qualquer. A partir da√≠, o **Armazenamento** √© a etapa de salvar esse dado em algum lugar
como, por exemplo, um computador ou um armaz√©m de dados.

Se voc√™ parar para pensar, coisas rotineiras podem ser enxergadas como ingest√£o: ao consultar seu
contracheque, por exemplo, voc√™ est√° realizando uma extra√ß√£o, ao requerer os dados no website de
consulta, e um armazenamento, ao baix√°-lo para seu computador.

### Transforma√ß√£o

A transforma√ß√£o de dados √© um conceito extremamente abrangente, ent√£o sua defini√ß√£o deve ser suficientemente
ampla: modificar um dado buscando um objetivo. Ent√£o, qualquer modifica√ß√£o no dado original √© considerada
uma transforma√ß√£o. Seguindo o exemplo do contracheque, uma poss√≠vel transforma√ß√£o seria a convers√£o de
moeda, caso voc√™ precisasse de um contracheque em d√≥lar.

Note que, ap√≥s a transforma√ß√£o, uma nova etapa de armazenamento √© realizada. Por√©m, esse dado transformado
poder√° sobrescrever o original, ou seja, o dado original n√£o ser√° mais acess√≠vel, ou coexistir com ele.

### Aplica√ß√£o

Essa √© a √∫ltima etapa de um fluxo de dados. Ela consiste em utilizar o dado para algum fim. Aqui se
encontram coisas como dashboards, aplicativos, chat bots e outros sendo, ent√£o, um pouco fora do
escopo desse guia.

Mas seguindo nosso exemplo do contracheque, uma poss√≠vel aplica√ß√£o seria a utiliza√ß√£o dos dados do
seu contracheque para a declara√ß√£o do IRPF.

### Considera√ß√µes finais

Como √© poss√≠vel notar pelo pr√≥prio diagrama, √© poss√≠vel iterar nesse fluxo indefinidamente. Ent√£o,
grandes projetos de dados n√£o usam somente um dado contido no armaz√©m, mas m√∫ltiplos, fazendo transforma√ß√µes
para un√≠-los e obter informa√ß√µes mais ricas. Tamb√©m, as transforma√ß√µes podem ocorrer indefinidamente,
at√© que se obtenha o resultado esperado.

## Apresenta√ß√£o dos componentes

Vamos incrementar aquele diagrama!

![Diagrama de componentes](../static/img/tutoriais/visao-geral-infra/visao-geral-componentes.jpg)

Aqui temos os componentes que comp√µem a infraestrutura de dados. Na parte de "Extra√ß√£o de dados",
temos o [Prefect](https://prefect.io/) para realizar a extra√ß√£o e [Google Cloud Storage](https://cloud.google.com/storage/)
[Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento. Logo mais, voc√™ ir√° entender
o que cada um faz e como foram selecionados.

J√° na parte de "Transforma√ß√µes", temos ali o [DBT](https://www.getdbt.com/) para realizar as transforma√ß√µes
e novamente o [Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento.

### Como chegamos a isso

Muitos pontos foram levantados durante o levantamento das ferramentas. Dentre eles, selecionamos um
conjunto dos que julgamos mais adequados para nossa infraestrutura que, de forma simplificada, √© o
seguinte:

- **Escalonamento**: todos os componentes devem funcionar bem para cargas de trabalho
  pequenas, mas devem ter a possibilidade de suportar cargas de trabalho enormes.
- **Liberdade**: como estamos hospedando nossos servi√ßos em nuvem, gostar√≠amos de ter a possibilidade
  de transitar entre provedores com facilidade. Por isso, sempre que razo√°vel, optamos por usar
  software livre.
- **Possibilidades**: poder usufruir por completo de uma linguagem de programa√ß√£o, como Python, ou
  de consulta, como SQL, permite fazer trabalhos extremamente complexos e replic√°veis.
- **Descentraliza√ß√£o**: hospedar cargas de trabalho de todos os √≥rg√£os da prefeitura em servidores
  separados permite um maior controle sobre os custos de cada √≥rg√£o e dificulta condi√ß√µes em que
  cargas de trabalho de um √≥rg√£o poderia onerar outro.
- **Simplicidade**: menos √© mais. Um sistema com poucos componentes √© mais f√°cil de manter e entender.

Claro que esses itens s√£o muito abstratos e, sabendo disso, constru√≠mos um instrumento de avalia√ß√£o
de servi√ßos com diversos fatores quantific√°veis e, a partir dele, conduzimos uma consulta p√∫blica
com v√°rios provedores de servi√ßos em nuvem, para que propusessem solu√ß√µes para nosso problema.

Ap√≥s a an√°lise, os componentes escolhidos foram os explicitados no diagrama acima. Agora vamos conversar
sobre cada um deles e explicar como eles funcionam.

### Extra√ß√£o (Prefect)

Como mencionado anteriormente, para realizar a extra√ß√£o de dados, a ferramenta selecionada foi o
[Prefect](https://prefect.io/). Essa √© uma ferramenta de c√≥digo aberto, que permite a automa√ß√£o
de quaisquer tarefas atrav√©s de sua API, em Python.

Por possuir uma interface muito simples de usar, √© extremamente f√°cil modificar seu c√≥digo para
usufruir de suas funcionalidades. Mas, para n√≥s, al√©m da linda interface que ele possui, os dois
itens que mais foram convidativos para n√≥s foram:

- **Confian√ßa**: √© muito f√°cil lidar com falhas no Prefect, voc√™ n√£o vai quebrar todo seu fluxo
  de dados se algo ruim acontecer. Al√©m disso, em nossos testes preliminares, conseguimos executar
  mais de 10 mil pipelines por dia, consumindo poucos recursos, sem problemas.
- **Modelo h√≠brido de execu√ß√£o**: esse deve ser o item mais apelativo para todos que aderem o Prefect.
  O [modelo h√≠brido](https://www.prefect.io/why-prefect/hybrid-model/) dele permite que voc√™ tenha o servidor
  hospedado em um local, seu c√≥digo em outro e o ambiente de execu√ß√£o em um terceiro. Existe uma clara
  separa√ß√£o de papeis que garante a seguran√ßa da execu√ß√£o do c√≥digo e, de tabela, uma completa descentraliza√ß√£o:
  podemos executar pipelines de um √≥rg√£o em um servidor, outro em outro e, ao mesmo tempo, conseguir
  enxergar todas elas em uma √∫nica interface.

E quando eu falo sobre facilidade de uso, eu realmente quero dizer que √© muito f√°cil. Olha s√≥ esse
exemplo: suponha que voc√™ tenha um c√≥digo de extra√ß√£o de dados em Python puro, d√° s√≥ uma olhada em
como port√°-lo para o Prefect.

=== "Python puro"

    ```py
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    def main():
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url)
        dataframe = montar_dataframe(data)
        salvar_dados(dataframe)
    ```

=== "Prefect"

    ```py
    from prefect import task, Flow

    @task
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    @task
    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    @task
    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    with Flow("main") as flow:
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url=url)
        dataframe = montar_dataframe(data=data)
        salvar_dados(dataframe=dataframe)
    ```

Bom demais, n√©?

### Transforma√ß√µes (DBT)

Aqui √© onde a galera do SQL se empolga. O [DBT](https://getdbt.com) √© uma ferramenta de c√≥digo aberto,
que permite a defini√ß√£o de modelos de dados em linguagem SQL. Ent√£o, em outras palavras, voc√™ pode
escrever uma query e, usando o DBT, materializar os resultados dessa query em diferentes formas e,
o que √© mais legal, em diferentes plataformas.

Assim, com a mesma query, voc√™ pode criar tabelas e _views_ em diferentes plataformas. E n√£o s√≥ isso,
as tabelas podem ser materializadas de maneiras diferentes, como, por exemplo, de forma incremental,
que consiste em adicionar novas linhas ao final de uma tabela.

Al√©m de tudo, voc√™ pode parametrizar suas queries para que elas sejam executadas com diferentes
valores de entrada. N√£o bastante, voc√™ pode especificar configura√ß√µes de particionamento, dentre
outras, diretamente no seu modelo de dados. D√° uma olhada s√≥ nesse exemplo:

```sql
{{
    config(
        materialized='table',
        partition_by={
            "field": "data_particao",
            "data_type": "date",
            "granularity": "month",
        }
    )
}}

SELECT
    *
FROM `datario.dataset_id.table_id`
```

Pode relaxar, voc√™ n√£o precisa entender tudo desse modelo ainda, teremos guias para isso. Mas, apesar
de curto, tem muita coisa rolando nesse modelo a√≠! Estamos especificando para ele que deve se materializar
em formato de tabela nativa com o `materialized='table'`, e estamos especificando que deve ser particionado
por data na coluna `data_particao` com uma granularidade mensal. Pouqu√≠ssimas linhas e simplesmente
funciona!

### Armazenamento (Google Cloud Storage e Google BigQuery)

Eu sei o que voc√™ vai dizer:

> Mas voc√™ disse "sempre que razo√°vel, optamos por usar software livre"

Sim, exatamente, sempre que razo√°vel. Por√©m, no caso do armazenamento, principalmente, as ferramentas
apresentadas pela Google atenderam todos os requisitos que hav√≠amos levantado, al√©m de reduzirem o
n√∫mero de componentes para dois ao inv√©s de m√∫ltiplos open-source que ter√≠amos que manter em conjunto.
Ok, vamos voltar ao que viemos fazer: apresentar os componentes.

- **Google Cloud Storage** √© um servi√ßo de armazenamento de objetos. Ent√£o, atrav√©s de uma API, √©
  poss√≠vel fazer upload de qualquer tipo de arquivo, configurar permiss√µes para ele e, caso tenha acesso,
  baix√°-lo novamente. Al√©m disso, voc√™ pode utiliz√°-lo como um _data lake_ em sua defini√ß√£o original -
  voc√™ pode armazenar arquivos na mesma estrutura de parti√ß√µes Hive e obter seus dados particionados
  para consulta. Voc√™, ent√£o, pode consultar seus dados com SQL no console do BigQuery.

- **Google BigQuery** √© um servi√ßo de _data warehouse serverless_. Ele permite an√°lises escalon√°veis
  em petabytes (mil terabytes) de dados. Como mencionado anteriormente, voc√™ pode consumir dados de
  _data lakes_ hospedados no Google Cloud Storage mas, ao mesmo tempo, pode criar tabelas nativas,
  que possuem performance muito superior.

E aqui, ent√£o, finalizamos a apresenta√ß√£o de nossos componentes. Mas calma, ainda tem muita coisa
a ser dita aqui, vamos em frente.

## Como est√£o hospedados

Agora que voc√™ conheceu os componentes, vamos entender onde eles est√£o. A medida que essa se√ß√£o avan√ßa,
iremos criar um diagrama e increment√°-lo aos poucos, at√© chegar na vis√£o completa.

### Prefect

Devido √† separa√ß√£o de pap√©is nativa do Prefect, vamos separar essa subse√ß√£o em tr√™s partes:

- O servidor: como estamos hospedando nosso back-end do Prefect, ser√° mostrado onde ele est√° e
  adapta√ß√µes que fizemos para seu funcionamento seguro.
- Os c√≥digos: mostraremos onde ele fica (todos podem acess√°-lo!)
- Os ambientes de execu√ß√£o: se voc√™ chegou a ler sobre o modelo h√≠brido do Prefect, sabe que ele
  depende de _agents_ para a execu√ß√£o de pipelines. Se voc√™ ainda n√£o sabe do que se trata, tudo
  certo, vamos abordar essa parte aqui tamb√©m.

#### Servidor

Esse subcomponente √© o respons√°vel por saber onde o c√≥digo mora, suas vers√µes, agendar execu√ß√µes,
armazenar hist√≥rico, exibir logs e relat√≥rios sobre o funcionamento do Prefect como um todo. Por√©m,
em sua vers√£o open-source, nativamente, ele n√£o possui qualquer tipo de camada de autentica√ß√£o para
realizar qualquer uma dessas opera√ß√µes (mas vamos abordar isso em breve aqui).

Ent√£o, para hosped√°-lo de forma que pud√©ssemos ter redund√¢ncia e facilidade para escalar, optamos
por usar um cluster Kubernetes. N√£o √© do escopo desse guia explicar o que √© um cluster Kubernetes,
mas, em poucas palavras e muito simplificadamente, pode ser visto como um grupo de m√°quinas que, a
partir de um controlador (em software) √© capaz de hospedar e gerenciar v√°rios containers. Vamos, ent√£o,
come√ßar nosso diagrama:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-01.png)

Simples at√© demais, n√£o √©? Sim, de fato. Poder√≠amos at√© nos contentar em mostrar isso, mas faltaria
muita informa√ß√£o para compreender como as coisas se comunicam. Ent√£o, vamos continuar. Para n√£o exagerar
nos detalhes, podemos considerar o cluster como uma √∫nica coisa, mas n√£o podemos esquecer que ele √©
composto de v√°rios computadores e que, necessariamente, esse computadores t√™m que estar conectados a
uma rede (isso permite que eles se comuniquem entre si e com a internet). Ent√£o, vamos incluir essa
parte do diagrama:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-02.png)

Sem problemas at√© aqui, vamos l√°: um conceito que tamb√©m √© utilizado em clusters Kubernetes √© o de
_namespace_: um espa√ßo de nomes que separa ambientes em um cluster. Claro, coisas hospedadas em um
namespace podem ser acessadas por outros namespaces, mas, devido a essa hierarquia, nomes iguais n√£o
ir√£o conflitar entre si.

Antes de incluir no diagrama, vamos a um exemplo: suponha que voc√™ deseje hospedar, em um mesmo cluster,
dois servidores (que podem ser coisas completamente distintas). Se voc√™ colocar o nome `servidor` em um
e quiser usar `servidor` no outro, como ele poderia distinguir ambos? A resposta para isso √© o _namespace_:
basta voc√™ hospedar cada um em um namespace diferente. Assim, quando voc√™ perguntar quem √© `servidor`,
voc√™ ter√° que informar o namespace e, assim, n√£o haver√° conflito. Claro que h√° outras possibilidades
a serem exploradas com namespaces, mas vamos manter isso para o momento e inclu√≠-lo no diagrama:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-03.png)

Pode n√£o parecer fazer diferen√ßa agora, mas vai fazer sentido mais pra frente, eu juro.

#### C√≥digo

Essa parte √© um pouco mais leve, vamos l√°: o c√≥digo de todas as nossas pipelines est√° versionado,
publicamente, no GitHub. Voc√™ pode acess√°-lo em [https://github.com/prefeitura-rio/pipelines](https://github.com/prefeitura-rio/pipelines).
Por√©m, para armazenamento que o Prefect usa, o c√≥digo √© hospedado no Google Cloud Storage.

Ent√£o, o fluxo de desenvolvimento de c√≥digo ocorre todo no GitHub e, quando alguma altera√ß√£o est√°
aprovada para ser publicada, ela automaticamente √© salva no Google Cloud Storage, que os ambientes
de execu√ß√£o do Prefect usam para buscar o c√≥digo. Vale ressaltar que quem informa ao ambiente de
execu√ß√£o onde o c√≥digo se encontra √© o servidor do Prefect. Por√©m, ele s√≥ sabe onde o c√≥digo est√°,
n√£o tem acesso a ele. Incluindo isso no diagrama, vamos l√°:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-04.png)

Est√° ficando complexo! Note que ainda n√£o abordamos como acontece a comunica√ß√£o entre o GitHub e o
servidor do Prefect, mas estamos chegando l√°.

#### Ambiente de execu√ß√£o

O ambiente √© gerido por _agents_, respons√°veis por "perguntar" ao servidor do Prefect se h√° alguma pipeline que precisa
ser executada e, se houver, lan√ßar uma execu√ß√£o para ela. Por√©m, nem toda execu√ß√£o pode ser lan√ßada
por qualquer agente. A separa√ß√£o, ent√£o, ocorre atrav√©s de _labels_: cada agente pode ser associado a
um ou mais labels, que s√£o usados para identificar qual pipelines (tamb√©m associadas a labels) ele
pode executar.

Entendido isso, vamos entender como ele se comunica com o servidor do Prefect. Lembra que comentei
ali em cima que a vers√£o open-source do servidor do Prefect n√£o possui camada de seguran√ßa nativa?
Pois √©, n√£o queremos que isso fique exposto, certo? Ent√£o, criamos uma camada de seguran√ßa para ele.
N√£o vou me aprofundar muito nesse assunto, pois n√£o √© o escopo do guia, ent√£o vou inclu√≠-la no diagrama
e corrig√≠-lo com rela√ß√£o a comunica√ß√£o do GitHub para que possamos continuar:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-05.png)

A ideia dessa mudan√ßa do diagrama √© s√≥ entender que existe uma forma segura de comunicar com o servidor
do Prefect atrav√©s da internet e que, consequentemente, todas as intera√ß√µes com o servidor do Prefect
s√£o intermediadas por um servidor de autentica√ß√£o.

> Mas o que isso tem a ver com o agente do Prefect?

Boa! Lembra que o agente do Prefect √© o respons√°vel por "perguntar" ao servidor do Prefect se h√° alguma
pipeline que precisa ser executada? Ent√£o, para isso, ele precisa tamb√©m interagir com o servidor de
autentica√ß√£o.

Mas falamos muito e at√© agora n√£o falamos onde esses agentes est√£o hospedados. E a√≠ √© que vem a parte
legal: em qualquer lugar! Como temos uma forma segura de comunica√ß√£o com o Prefect atrav√©s da internet,
desde que os agentes tenham acesso √† internet, eles podem estar em qualquer lugar! Ent√£o, para fins de
exemplifica√ß√£o, vamos incluir nesse esquema a√≠ os seguintes agentes:

- `rj-escritorio`: um agente nosso, do Escrit√≥rio de Dados. Ele vai ficar hospedado no mesmo cluster
  do servidor do Prefect, por√©m em um namespace diferente (voc√™ vai logo entender o motivo).
- `rj-escritorio-dev`: outro agente do Escrit√≥rio de Dados, mas para desenvolvimento. Isso significa
  que, caso tenhamos desenvolvido uma pipeline que est√° est√°vel, mas ainda queremos test√°-la bastante
  antes de deix√°-la definitiva, ela pode ser executada com esse agente. Ele tamb√©m vai ficar hospedado
  em um namespace exclusivo.
- `rj-orgao`: um agente de um √≥rg√£o qualquer da prefeitura. Ele vai ficar hospedado em um outro cluster
  Kubernetes, (nesse cen√°rio) pertencente a outro √≥rg√£o. Isso permite uma clara divis√£o de custos com
  infraestrutura, j√° que quem arcar√° com os custos das execu√ß√µes de pipelines do √≥rg√£o √© o pr√≥prio √≥rg√£o.

Incluindo no diagrama:

![Diagrama de hospedagem](../static/img/tutoriais/visao-geral-infra/hospedagem-06.png)

### DBT

A hospedagem do DBT √© razoavelmente simples. O modo que utilizamos para hosped√°-lo √© atrav√©s de um
servidor RPC, que cont√©m os modelos de dados definidos e credenciais de acesso √† plataforma onde
ele ir√° operar. Ent√£o, para materializar os modelos de dados, √© necess√°rio pedir ao servidor RPC,
atrav√©s das pipelines do Prefect, que far√° essa tarefa e informar√° se foi bem sucedida ou n√£o.

Os modelos de dados est√£o definidos em reposit√≥rios do GitHub, um para cada √≥rg√£o. Os nomes dos
reposit√≥rios seguem o padr√£o `queries-rj-<nome do √≥rg√£o>`. Ent√£o, por exemplo, o reposit√≥rio
[queries-rj-escritorio](https://github.com/prefeitura-rio/queries-rj-escritorio) cont√©m os modelos
de dados do √≥rg√£o Escrit√≥rio de Dados.

Al√©m desses reposit√≥rios, existe um reposit√≥rio [queries-datario](https://github.com/prefeitura-rio/queries-datario),
que define os modelos de dados que ser√£o publicados no [data.rio](https://www.data.rio).

O que acontece √© que, quando s√£o realizadas altera√ß√µes nesses modelos de dados, uma inst√¢ncia atualizada
do servidor RPC √© criada exatamente no mesmo cluster e namespace onde o agente do Prefect correspondente
est√° hospedado. Ent√£o, por exemplo, para o reposit√≥rio [queries-rj-escritorio](https://github.com/prefeitura-rio/queries-rj-escritorio),
ser√° criado um servidor RPC atualizado para os namespaces `rj-escritorio` e `rj-escritorio-dev`, j√°
mostrados acima.

E √© aqui que o conceito de namespace fica mais relevante, olha s√≥:

- Para materializar um modelo de dados, as pipelines precisam solicitar ao servidor RPC do DBT
- As pipelines s√£o executadas no mesmo namespace onde o agente do Prefect est√° hospedado
- O servidor RPC do DBT √© criado para cada namespace

Ent√£o, se eu estiver no namespace `rj-escritorio` e perguntar pelo servidor RPC do DBT, eu terei acesso
somente aos modelos de dados definidos em [queries-rj-escritorio](https://github.com/prefeitura-rio/queries-rj-escritorio).
Analogamente, se eu estiver nesse namespace `rj-orgao`, eu terei acesso somente aos modelos de dados
desse √≥rg√£o.

> Explicar como as coisas s√£o hospedadas, falar da descentraliza√ß√£o, escalabilidade, Kubernetes,
> reposit√≥rios, GitHub Actions, etc.

## Comunica√ß√£o e intera√ß√µes

> Os componentes precisam se comunicar pra fazer com que tudo funcione. Mencionar como isso √© feito,
> falar do basedosdados que √© um pacote importante que a gente usa, etc. Falar do BigQuery, GCS,

Com os dados prontos para subir para o _data lake_, utilizaremos o pacote `basedosdados` (disponivel
em Python ou CLI) para orquestrar todo esse processo. Os dados iram passar por nossos componentes de
armazenamento:

1. **Google Cloud Storage (GCS)**: local onde ser√£o armazenados os arquivos brutos, geralmente `.csv`, mas
   tamb√©m aceita outros formatos como `.parquet` e arquivos compactados.
2. **Google BigQuery (BQ)**: nossas tabelas ser√£o separadas em dois datasets: o de **staging**, que ter√° o
   nome no formato `dataset_id_staging`, cont√©m as tabelas externas geradas a partir dos dados brutos
   hospedados no **GCS**. J√° o de **produ√ß√£o**, com nome no formato `dataset_id`, cont√©m as tabelas
   nativas j√° tratadas e padronizadas geradas pelo **DBT**.

A primeira etapa realizada pelo pacote `basedosdados` √© o upload dos dados para o **GCS**....

> tabelas externas, etc.
