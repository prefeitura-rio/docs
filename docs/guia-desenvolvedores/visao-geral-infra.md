E a√≠, quer entender melhor nossa infraestrutura de dados, os componentes selecionados, como interagem
entre si e onde est√£o hospedados? Ent√£o vamos l√°! üë®‚Äçüíª

## Introdu√ß√£o ao fluxo de dados

N√£o h√° nada extravagante em nosso fluxo de dados, na realidade, ele √© t√£o intuitivo quanto pode ser.
No entanto, √© muito importante entender cada etapa para que seja poss√≠vel compreender o funcionamento
da infraestrutura como um todo.

Ent√£o, vamos colocar aqui um diagrama que ajudar√° a entender por onde o dado transita e no que consistem
as etapas:

![Diagrama de etapas de processamento dos dados](../static/img/tutoriais/visao-geral-infra/visao-geral-sem-componentes.jpg)

Como estamos falando sobre a infraestrutura de dados, vamos focar √∫nica e exclusivamente na parte
central desse diagrama, ou seja, as tr√™s grandes etapas - Ingest√£o, Transforma√ß√£o e Aplica√ß√£o - e o
bloco central, o Armaz√©m de Dados.

### Armaz√©m de dados

Como o pr√≥prio nome j√° diz, √© o local onde os dados s√£o armazenados. No entanto, n√£o √© uma ferramenta
t√£o simples quanto o nome faz parecer, dado que √© o componente central do fluxo de dados e, portanto,
deve suportar uma grande variedade de opera√ß√µes, al√©m de uma imensa capacidade de processamento e
armazenamento, visto que os dados podem ter tamanhos e prioridades diferentes.

Mais especificamente, uma ferramenta de armaz√©m de dados para nossa infraestrutura deve possuir as
seguintes funcionalidades:

- **Capacidade de armazenamento e processamento "ilimitada"**: n√£o queremos nos preocupar em qual o tamanho do dado
  que vamos armazenar, n√≥s o queremos e ponto!
- **Otimiza√ß√£o de processamento via particionamento e correlatos**: para dados de grande volume, √©
  sempre interessante recorrer a mecanismos de particionamento e semelhantes para otimizar o processamento
  e, consequentemente, os custos de uma consulta.
- **Suporte a SQL**: n√≥s queremos usar a linguagem de consulta mais popular e acess√≠vel at√© o momento.
- **Fun√ß√µes de an√°lise geoespacial**: por se tratar de dados da cidade s√£o, em maioria, geolocalizados.
  Assim, ter funcionalidades de an√°lise geoespacial √© fundamental.
- **Governan√ßa simplificada**: ter uma interface amig√°vel para gerir o armaz√©m de dados √© fundamental.
- **Conex√µes com plataformas de desenvolvimento de dashboards**: n√£o adianta ter dados se n√£o conseguimos
  visualiz√°-los ou us√°-los.
- **Possibilidade de disponibilizar os dados publicamente**: afinal, queremos que a comunidade acesse!

### Ingest√£o

A ingest√£o √© o ato de obter um dado e traz√™-lo para seu ambiente. Ela consiste em duas subetapas: a
extra√ß√£o e o armazenamento.

A **Extra√ß√£o** √© ato de adquirir o dado a partir de alguma fonte, como um banco de dados, uma API ou
um arquivo qualquer. A partir da√≠, o **Armazenamento** √© a etapa de salvar esse dado em algum lugar
como, por exemplo, um computador ou um armaz√©m de dados.

Se voc√™ parar para pensar, coisas rotineiras podem ser enxergadas como ingest√£o: ao consultar seu
contracheque, por exemplo, voc√™ est√° realizando uma extra√ß√£o, ao requerer os dados no website de
consulta, e um armazenamento, ao baix√°-lo para seu computador.

### Transforma√ß√£o

A transforma√ß√£o de dados √© um conceito extremamente abrangente, ent√£o sua defini√ß√£o deve ser suficientemente
ampla: modificar um dado buscando um objetivo. Ent√£o, qualquer modifica√ß√£o no dado original √© considerada
uma transforma√ß√£o. Seguindo o exemplo do contracheque, uma poss√≠vel transforma√ß√£o seria a convers√£o de
moeda, caso voc√™ precisasse de um contracheque em d√≥lar.

Note que, ap√≥s a transforma√ß√£o, uma nova etapa de armazenamento √© realizada. Por√©m, esse dado transformado
poder√° sobrescrever o original, ou seja, o dado original n√£o ser√° mais acess√≠vel, ou coexistir com ele.

### Aplica√ß√£o

Essa √© a √∫ltima etapa de um fluxo de dados. Ela consiste em utilizar o dado para algum fim. Aqui se
encontram coisas como dashboards, aplicativos, chat bots e outros sendo, ent√£o, um pouco fora do
escopo desse guia.

Mas seguindo nosso exemplo do contracheque, uma poss√≠vel aplica√ß√£o seria a utiliza√ß√£o dos dados do
seu contracheque para a declara√ß√£o do IRPF.

### Considera√ß√µes finais

Como √© poss√≠vel notar pelo pr√≥prio diagrama, √© poss√≠vel iterar nesse fluxo indefinidamente. Ent√£o,
grandes projetos de dados n√£o usam somente um dado contido no armaz√©m, mas m√∫ltiplos, fazendo transforma√ß√µes
para un√≠-los e obter informa√ß√µes mais ricas. Tamb√©m, as transforma√ß√µes podem ocorrer indefinidamente,
at√© que se obtenha o resultado esperado.

## Apresenta√ß√£o dos componentes

Vamos incrementar aquele diagrama!

![Diagrama de componentes](../static/img/tutoriais/visao-geral-infra/visao-geral-componentes.jpg)

Aqui temos os componentes que comp√µem a infraestrutura de dados. Na parte de "Extra√ß√£o de dados",
temos o [Prefect](https://prefect.io/) para realizar a extra√ß√£o e [Google Cloud Storage](https://cloud.google.com/storage/)
[Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento. Logo mais, voc√™ ir√° entender
o que cada um faz e como foram selecionados.

J√° na parte de "Transforma√ß√µes", temos ali o [DBT](https://www.getdbt.com/) para realizar as transforma√ß√µes
e novamente o [Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento.

### Como chegamos a isso

Muitos pontos foram levantados durante o levantamento das ferramentas. Dentre eles, selecionamos um
conjunto dos que julgamos mais adequados para nossa infraestrutura que, de forma simplificada, √© o
seguinte:

- **Escalonamento**: todos os componentes devem funcionar bem para cargas de trabalho
  pequenas, mas devem ter a possibilidade de suportar cargas de trabalho enormes.
- **Liberdade**: como estamos hospedando nossos servi√ßos em nuvem, gostar√≠amos de ter a possibilidade
  de transitar entre provedores com facilidade. Por isso, sempre que razo√°vel, optamos por usar
  software livre.
- **Possibilidades**: poder usufruir por completo de uma linguagem de programa√ß√£o, como Python, ou
  de consulta, como SQL, permite fazer trabalhos extremamente complexos e replic√°veis.
- **Descentraliza√ß√£o**: hospedar cargas de trabalho de todos os √≥rg√£os da prefeitura em servidores
  separados permite um maior controle sobre os custos de cada √≥rg√£o e dificulta condi√ß√µes em que
  cargas de trabalho de um √≥rg√£o poderia onerar outro.
- **Simplicidade**: menos √© mais. Um sistema com poucos componentes √© mais f√°cil de manter e entender.

Claro que esses itens s√£o muito abstratos e, sabendo disso, constru√≠mos um instrumento de avalia√ß√£o
de servi√ßos com diversos fatores quantific√°veis e, a partir dele, conduzimos uma consulta p√∫blica
com v√°rios provedores de servi√ßos em nuvem, para que propusessem solu√ß√µes para nosso problema.

Ap√≥s a an√°lise, os componentes escolhidos foram os explicitados no diagrama acima. Agora vamos conversar
sobre cada um deles e explicar como eles funcionam.

### Extra√ß√£o (Prefect)

Como mencionado anteriormente, para realizar a extra√ß√£o de dados, a ferramenta selecionada foi o
[Prefect](https://prefect.io/). Essa √© uma ferramenta de c√≥digo aberto, que permite a automa√ß√£o
de quaisquer tarefas atrav√©s de sua API, em Python.

Por possuir uma interface muito simples de usar, √© extremamente f√°cil modificar seu c√≥digo para
usufruir de suas funcionalidades. Mas, para n√≥s, al√©m da linda interface que ele possui, os dois
itens que mais foram convidativos para n√≥s foram:

- **Confian√ßa**: √© muito f√°cil lidar com falhas no Prefect, voc√™ n√£o vai quebrar todo seu fluxo
  de dados se algo ruim acontecer. Al√©m disso, em nossos testes preliminares, conseguimos executar
  mais de 10 mil pipelines por dia, consumindo poucos recursos, sem problemas.
- **Modelo h√≠brido de execu√ß√£o**: esse deve ser o item mais apelativo para todos que aderem o Prefect.
  O [modelo h√≠brido](https://www.prefect.io/why-prefect/hybrid-model/) dele permite que voc√™ tenha o servidor
  hospedado em um local, seu c√≥digo em outro e o ambiente de execu√ß√£o em um terceiro. Existe uma clara
  separa√ß√£o de papeis que garante a seguran√ßa da execu√ß√£o do c√≥digo e, de tabela, uma completa descentraliza√ß√£o:
  podemos executar pipelines de um √≥rg√£o em um servidor, outro em outro e, ao mesmo tempo, conseguir
  enxergar todas elas em uma √∫nica interface.

E quando eu falo sobre facilidade de uso, eu realmente quero dizer que √© muito f√°cil. Olha s√≥ esse
exemplo: suponha que voc√™ tenha um c√≥digo de extra√ß√£o de dados em Python puro, d√° s√≥ uma olhada em
como port√°-lo para o Prefect.

=== "Python puro"

    ```py
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    def main():
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url)
        dataframe = montar_dataframe(data)
        salvar_dados(dataframe)
    ```

=== "Prefect"

    ```py
    from prefect import task, Flow

    @task
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    @task
    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    @task
    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    with Flow("main") as flow:
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url=url)
        dataframe = montar_dataframe(data=data)
        salvar_dados(dataframe=dataframe)
    ```

Bom demais, n√©?

### Transforma√ß√µes (DBT)

Aqui √© onde a galera do SQL se empolga. O [DBT](https://getdbt.com) √© uma ferramenta de c√≥digo aberto,
que permite a defini√ß√£o de modelos de dados em linguagem SQL. Ent√£o, em outras palavras, voc√™ pode
escrever uma query e, usando o DBT, materializar os resultados dessa query em diferentes formas e,
o que √© mais legal, em diferentes plataformas.

Assim, com a mesma query, voc√™ pode criar tabelas e _views_ em diferentes plataformas. E n√£o s√≥ isso,
as tabelas podem ser materializadas de maneiras diferentes, como, por exemplo, de forma incremental,
que consiste em adicionar novas linhas ao final de uma tabela.

Al√©m de tudo, voc√™ pode parametrizar suas queries para que elas sejam executadas com diferentes
valores de entrada. N√£o bastante, voc√™ pode especificar configura√ß√µes de particionamento, dentre
outras, diretamente no seu modelo de dados. D√° uma olhada s√≥ nesse exemplo:

```sql
{{
    config(
        materialized='table',
        partition_by={
            "field": "data_particao",
            "data_type": "date",
            "granularity": "month",
        }
    )
}}

SELECT
    *
FROM `datario.dataset_id.table_id`
```

Pode relaxar, voc√™ n√£o precisa entender tudo desse modelo ainda, teremos guias para isso. Mas, apesar
de curto, tem muita coisa rolando nesse modelo a√≠! Estamos especificando para ele que deve se materializar
em formato de tabela nativa com o `materialized='table'`, e estamos especificando que deve ser particionado
por data na coluna `data_particao` com uma granularidade mensal. Pouqu√≠ssimas linhas e simplesmente
funciona!

### Armazenamento (Google Cloud Storage e Google BigQuery)

Eu sei o que voc√™ vai dizer:

> Mas voc√™ disse "sempre que razo√°vel, optamos por usar software livre"

Sim, exatamente, sempre que razo√°vel. Por√©m, no caso do armazenamento, principalmente, as ferramentas
apresentadas pela Google atenderam todos os requisitos que hav√≠amos levantado, al√©m de reduzirem o
n√∫mero de componentes para dois ao inv√©s de m√∫ltiplos open-source que ter√≠amos que manter em conjunto.
Ok, vamos voltar ao que viemos fazer: apresentar os componentes.

- **Google Cloud Storage** √© um servi√ßo de armazenamento de objetos. Ent√£o, atrav√©s de uma API, √©
  poss√≠vel fazer upload de qualquer tipo de arquivo, configurar permiss√µes para ele e, caso tenha acesso,
  baix√°-lo novamente. Al√©m disso, voc√™ pode utiliz√°-lo como um _data lake_ em sua defini√ß√£o original -
  voc√™ pode armazenar arquivos na mesma estrutura de parti√ß√µes Hive e obter seus dados particionados
  para consulta. Voc√™, ent√£o, pode consultar seus dados com SQL no console do BigQuery.

- **Google BigQuery** √© um servi√ßo de _data warehouse serverless_. Ele permite an√°lises escalon√°veis
  em petabytes (mil terabytes) de dados. Como mencionado anteriormente, voc√™ pode consumir dados de
  _data lakes_ hospedados no Google Cloud Storage mas, ao mesmo tempo, pode criar tabelas nativas,
  que possuem performance muito superior.

E aqui, ent√£o, finalizamos a apresenta√ß√£o de nossos componentes. Mas calma, ainda tem muita coisa
a ser dita aqui, vamos em frente.

## Como est√£o hospedados

> Explicar como as coisas s√£o hospedadas, falar da descentraliza√ß√£o, escalabilidade, Kubernetes,
> reposit√≥rios, GitHub Actions, etc.

## Comunica√ß√£o e intera√ß√µes

> Os componentes precisam se comunicar pra fazer com que tudo funcione. Mencionar como isso √© feito,
> falar do basedosdados que √© um pacote importante que a gente usa, etc. Falar do BigQuery, GCS,
> tabelas externas, etc.
