E a√≠, quer entender melhor nossa infraestrutura de dados, os componentes selecionados, como interagem
entre si e onde est√£o hospedados? Ent√£o vamos l√°! üë®‚Äçüíª

## Introdu√ß√£o ao fluxo de dados

N√£o h√° nada extravagante em nosso fluxo de dados, na realidade, ele √© t√£o intuitivo quanto pode ser.
No entanto, √© muito importante entender cada etapa para que seja poss√≠vel compreender o funcionamento
da infraestrutura como um todo.

Ent√£o, vamos colocar aqui um diagrama que ajudar√° a entender por onde o dado transita e no que consistem
as etapas:

![Diagrama de etapas de processamento dos dados](../static/img/tutoriais/visao-geral-infra/visao-geral-sem-componentes.jpg)

Como estamos falando sobre a infraestrutura de dados, vamos focar √∫nica e exclusivamente na parte
central desse diagrama, ou seja, as tr√™s grandes etapas - Ingest√£o, Transforma√ß√£o e Aplica√ß√£o - e o
bloco central, o Armaz√©m de Dados.

### Armaz√©m de dados

Como o pr√≥prio nome j√° diz, √© o local onde os dados s√£o armazenados. No entanto, n√£o √© uma ferramenta
t√£o simples quanto o nome faz parecer, dado que √© o componente central do fluxo de dados e, portanto,
deve suportar uma grande variedade de opera√ß√µes, al√©m de uma imensa capacidade de processamento e
armazenamento, visto que os dados podem ter tamanhos e prioridades diferentes.

Mais especificamente, uma ferramenta de armaz√©m de dados para nossa infraestrutura deve possuir as
seguintes funcionalidades:

- **Capacidade de armazenamento e processamento "ilimitada"**: n√£o queremos nos preocupar em qual o tamanho do dado
  que vamos armazenar, n√≥s o queremos e ponto!
- **Otimiza√ß√£o de processamento via particionamento e correlatos**: para dados de grande volume, √©
  sempre interessante recorrer a mecanismos de particionamento e semelhantes para otimizar o processamento
  e, consequentemente, os custos de uma consulta.
- **Suporte a SQL**: n√≥s queremos usar a linguagem de consulta mais popular e acess√≠vel at√© o momento.
- **Fun√ß√µes de an√°lise geoespacial**: por se tratar de dados da cidade s√£o, em maioria, geolocalizados.
  Assim, ter funcionalidades de an√°lise geoespacial √© fundamental.
- **Governan√ßa simplificada**: ter uma interface amig√°vel para gerir o armaz√©m de dados √© fundamental.
- **Conex√µes com plataformas de desenvolvimento de dashboards**: n√£o adianta ter dados se n√£o conseguimos
  visualiz√°-los ou us√°-los.
- **Possibilidade de disponibilizar os dados publicamente**: afinal, queremos que a comunidade acesse!

### Ingest√£o

A ingest√£o √© o ato de obter um dado e traz√™-lo para seu ambiente. Ela consiste em duas subetapas: a
extra√ß√£o e o armazenamento.

A **Extra√ß√£o** √© ato de adquirir o dado a partir de alguma fonte, como um banco de dados, uma API ou
um arquivo qualquer. A partir da√≠, o **Armazenamento** √© a etapa de salvar esse dado em algum lugar
como, por exemplo, um computador ou um armaz√©m de dados.

Se voc√™ parar para pensar, coisas rotineiras podem ser enxergadas como ingest√£o: ao consultar seu
contracheque, por exemplo, voc√™ est√° realizando uma extra√ß√£o, ao requerer os dados no website de
consulta, e um armazenamento, ao baix√°-lo para seu computador.

### Transforma√ß√£o

A transforma√ß√£o de dados √© um conceito extremamente abrangente, ent√£o sua defini√ß√£o deve ser suficientemente
ampla: modificar um dado buscando um objetivo. Ent√£o, qualquer modifica√ß√£o no dado original √© considerada
uma transforma√ß√£o. Seguindo o exemplo do contracheque, uma poss√≠vel transforma√ß√£o seria a convers√£o de
moeda, caso voc√™ precisasse de um contracheque em d√≥lar.

Note que, ap√≥s a transforma√ß√£o, uma nova etapa de armazenamento √© realizada. Por√©m, esse dado transformado
poder√° sobrescrever o original, ou seja, o dado original n√£o ser√° mais acess√≠vel, ou coexistir com ele.

### Aplica√ß√£o

Essa √© a √∫ltima etapa de um fluxo de dados. Ela consiste em utilizar o dado para algum fim. Aqui se
encontram coisas como dashboards, aplicativos, chat bots e outros sendo, ent√£o, um pouco fora do
escopo desse guia.

Mas seguindo nosso exemplo do contracheque, uma poss√≠vel aplica√ß√£o seria a utiliza√ß√£o dos dados do
seu contracheque para a declara√ß√£o do IRPF.

### Considera√ß√µes finais

Como √© poss√≠vel notar pelo pr√≥prio diagrama, √© poss√≠vel iterar nesse fluxo indefinidamente. Ent√£o,
grandes projetos de dados n√£o usam somente um dado contido no armaz√©m, mas m√∫ltiplos, fazendo transforma√ß√µes
para un√≠-los e obter informa√ß√µes mais ricas. Tamb√©m, as transforma√ß√µes podem ocorrer indefinidamente,
at√© que se obtenha o resultado esperado.

## Apresenta√ß√£o dos componentes

Vamos incrementar aquele diagrama!

![Diagrama de componentes](../static/img/tutoriais/visao-geral-infra/visao-geral-componentes.jpg)

Aqui temos os componentes que comp√µem a infraestrutura de dados. Na parte de "Extra√ß√£o de dados",
temos o [Prefect](https://prefect.io/) para realizar a extra√ß√£o e [Google Cloud Storage](https://cloud.google.com/storage/)
[Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento. Logo mais, voc√™ ir√° entender
o que cada um faz e como foram selecionados.

J√° na parte de "Transforma√ß√µes", temos ali o [DBT](https://www.getdbt.com/) para realizar as transforma√ß√µes
e novamente o [Google BigQuery](https://cloud.google.com/bigquery/) para armazenamento.

### Como chegamos a isso

Muitos pontos foram levantados durante o levantamento das ferramentas. Dentre eles, selecionamos um
conjunto dos que julgamos mais adequados para nossa infraestrutura que, de forma simplificada, √© o
seguinte:

- **Escalonamento**: todos os componentes devem funcionar bem para cargas de trabalho
  pequenas, mas devem ter a possibilidade de suportar cargas de trabalho enormes.
- **Liberdade**: como estamos hospedando nossos servi√ßos em nuvem, gostar√≠amos de ter a possibilidade
  de transitar entre provedores com facilidade. Por isso, sempre que razo√°vel, optamos por usar
  software livre.
- **Possibilidades**: poder usufruir por completo de uma linguagem de programa√ß√£o, como Python, ou
  de consulta, como SQL, permite fazer trabalhos extremamente complexos e replic√°veis.
- **Descentraliza√ß√£o**: hospedar cargas de trabalho de todos os √≥rg√£os da prefeitura em servidores
  separados permite um maior controle sobre os custos de cada √≥rg√£o e dificulta condi√ß√µes em que
  cargas de trabalho de um √≥rg√£o poderia onerar outro.
- **Simplicidade**: menos √© mais. Um sistema com poucos componentes √© mais f√°cil de manter e entender.

Claro que esses itens s√£o muito abstratos e, sabendo disso, constru√≠mos um instrumento de avalia√ß√£o
de servi√ßos com diversos fatores quantific√°veis e, a partir dele, conduzimos uma consulta p√∫blica
com v√°rios provedores de servi√ßos em nuvem, para que propusessem solu√ß√µes para nosso problema.

Ap√≥s a an√°lise, os componentes escolhidos foram os explicitados no diagrama acima. Agora vamos conversar
sobre cada um deles e explicar como eles funcionam.

### Extra√ß√£o (Prefect)

Como mencionado anteriormente, para realizar a extra√ß√£o de dados, a ferramenta selecionada foi o
[Prefect](https://prefect.io/). Essa √© uma ferramenta de c√≥digo aberto, que permite a automa√ß√£o
de quaisquer tarefas atrav√©s de sua API, em Python.

Por possuir uma interface muito simples de usar, √© extremamente f√°cil modificar seu c√≥digo para
usufruir de suas funcionalidades. Mas, para n√≥s, al√©m da linda interface que ele possui, os dois
itens que mais foram convidativos para n√≥s foram:

- **Confian√ßa**: √© muito f√°cil lidar com falhas no Prefect, voc√™ n√£o vai quebrar todo seu fluxo
  de dados se algo ruim acontecer. Al√©m disso, em nossos testes preliminares, conseguimos executar
  mais de 10 mil pipelines por dia, consumindo poucos recursos, sem problemas.
- **Modelo h√≠brido de execu√ß√£o**: esse deve ser o item mais apelativo para todos que aderem o Prefect.
  O [modelo h√≠brido](https://www.prefect.io/why-prefect/hybrid-model/) dele permite que voc√™ tenha o servidor
  hospedado em um local, seu c√≥digo em outro e o ambiente de execu√ß√£o em um terceiro. Existe uma clara
  separa√ß√£o de papeis que garante a seguran√ßa da execu√ß√£o do c√≥digo e, de tabela, uma completa descentraliza√ß√£o:
  podemos executar pipelines de um √≥rg√£o em um servidor, outro em outro e, ao mesmo tempo, conseguir
  enxergar todas elas em uma √∫nica interface.

E quando eu falo sobre facilidade de uso, eu realmente quero dizer que √© muito f√°cil. Olha s√≥ esse
exemplo: suponha que voc√™ tenha um c√≥digo de extra√ß√£o de dados em Python puro, d√° s√≥ uma olhada em
como port√°-lo para o Prefect.

=== "Python puro"

    ```py
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    def main():
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url)
        dataframe = montar_dataframe(data)
        salvar_dados(dataframe)
    ```

=== "Prefect"

    ```py
    from prefect import task, Flow

    @task
    def extrair_dados(url):
        response = requests.get(url)
        data = response.json()
        return data

    @task
    def montar_dataframe(data):
        df = pd.DataFrame(data)
        return df

    @task
    def salvar_dados(dataframe):
        dataframe.to_csv('dados.csv')

    with Flow("main") as flow:
        url = 'https://url.da.api.que.voce.quer.extrair'
        data = extrair_dados(url=url)
        dataframe = montar_dataframe(data=data)
        salvar_dados(dataframe=dataframe)
    ```

Bom demais, n√©?

### Transforma√ß√µes (DBT)

To do.

### Armazenamento (Google Cloud Storage e Google BigQuery)

To do.

## Como est√£o hospedados

> Explicar como as coisas s√£o hospedadas, falar da descentraliza√ß√£o, escalabilidade, Kubernetes,
> reposit√≥rios, GitHub Actions, etc.

## Comunica√ß√£o e intera√ß√µes

> Os componentes precisam se comunicar pra fazer com que tudo funcione. Mencionar como isso √© feito,
> falar do basedosdados que √© um pacote importante que a gente usa, etc. Falar do BigQuery, GCS,

Com os dados prontos para subir para o Datalake, utilizaremos o pacote `basedosdados` (disponivel em Python ou CLI) para orquestrar todo esse processo. Os dados iram passar por 2 componentes do Google Cloud;

    1. `Storage`: local onde ser√£o armazenados os arquivos brutos, geralmente `.csv`, mas tamb√©m aceita outros formatos como `parquet` e arquivos compactados.
    2. `Bigquery`: Super banco de dados do Google. Nossas tabelas seram separadas em 2 tipos de datasets, 
       - `Staging`: Dataset do tipo `dataset_id_staging`. Contem as tabelas externas geradas a partir dos dados brutos que est√£o hospedados no `storage`
       - `Producao`: Dataset do tipo `dataset_id`. Contem as tabelas nativas j√° tratadas e padronizadas geradas pelo `DBT`


A primeira etapa realizada pelo pacote `basedosdados` √© o upload dos dados para o `Storage`....



> tabelas externas, etc.

```

```
